{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "## LOCAL RELATIONSHIP : 인근 픽셀들끼리 관계가 더 깊다\n",
    "\n",
    "#COVOULUTION LAYER : 필터를 통해서 부분부분 자른다\n",
    "#ACTIVATION LAYER  : 비선형을 위해 사용 일반적으로 RELU\n",
    "#POOLING LAYER : 나온 LAYER를 샘플링한다, RESIZE 효과, SUB-SAMPLING, OVERFITTING을 방지하기 위함, 압축\n",
    "\n",
    "#FULLY CONNECTED LAYER : INPUT값집어넣어서 OUT값 내는"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER의 DEPTH(RGB 컬러)는 처음 인풋과 맞춰야한다\n",
    "\n",
    "# 필터사이즈만큼 element wise 방식으로 곱해서 모두 더함 -> 필터가 지나간 자리에 하나의 y값만 남음\n",
    "# ex) 5*5*3 필터를 쓸때 같은 인덱스끼리 다 곱하고 다 더한게 y 값이됨 x는 내가본 이미지, w는 필터,b는 로직에 노영향\n",
    "# 한칸씩 움직일때 stride를 1씩줬다고한다\n",
    "\n",
    "# pad를 하면 stride로 나눠지지 않는부분을 0으로 채워서 이미지가 유지가되고, 가장자리 info를 줄 수 있다\n",
    "\n",
    "#필터는 랜덤초기화이기 때문에 각각 다르다\n",
    "# 필터의 갯수(depth)가 출력값의 depth가 된다 , depth는 그냥 depth ㅎㅎ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling, 중요한 정보만 뽑아내고 나머지 머리자\n",
    "\n",
    "# max pooling 필터가 본것중에 가장 큰것만 뽑아낸다\n",
    "# average, min 등 여러가지가 있지만 일반적으로 max pooling을 마니씀\n",
    "\n",
    "#후반부에는 추상화 부분만 남는다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x523e0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array([[[[1],[2],[3]],\n",
    "                  [[4],[5],[6]],\n",
    "                  [[7],[8],[9]]]], dtype=np.float32)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(image.shape) #이미지의 shape (이미지개수 * 가로 * 세로 * 높이)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter shape : (2, 2, 1, 1)\n",
      "(1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tf 에선 이미지와 필터 위치가 바뀐다\n",
    "\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                     [[[1.]],[[1.]]]]) \n",
    "\n",
    "#filter shape (가로 *세로 *높이 *갯수(depth))\n",
    "\n",
    "print('Filter shape :',weight.shape)\n",
    "# conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='VALID') #strides 순서는[위,오른,밑,왼]\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='SAME') #원래 인풋사이즈랑 똑같은 사이즈\n",
    "#PADDING 맞추는 순서는 가로는 오른쪽 부터, 세로는 아래부터해서 나머지 왼쪽, 위쪽으로 맞춰간다\n",
    "\n",
    "conv2d_img = conv2d.eval()\n",
    "print(conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img,0,3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    # enumerate하면 키, value 가 나온다!!!\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(one_img.reshape(3,3), cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1, 3)\n",
      "(1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAC7CAYAAADPLLrPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACVFJREFUeJzt3X+o3XUdx/HnK3ULcTVz1sb8GV0k+2U6pyLITAY6xAkZXP/IHygXROkHBWmBQRCs/iiyhWEpZoQaFrlkIZNZGqXuTqZujumSwOnAvOZsuJLVuz/OtzqdnXvfd/t+7uecu/t6wOF+v+f7uff9OVxefM/3fL/n/VVEYGaTe9egJ2A27BwSs4RDYpZwSMwSDolZwiExS7QKiaT3Sdog6cXm57GTjPunpC3NY12bmma1qc15EknfBt6IiDWSbgaOjYiv9Bm3NyKOaTFPs4FpG5IdwIqI2C1pCfDbiDitzziHxGattsckH4iI3QDNz/dPMu7dksYlPSHp8pY1zao6Mhsg6RFgcZ9NXzuIOidFxKuSPghslPRcRPypT60xYAzg6KOPPmtkZOQgSgyvffv2DXoKxSxYsGDQUyhm8+bNr0fE8dm4Km+3en7nbuChiHhgqnFnnHFGbNiw4ZDnNky2bt066CkUc+GFFw56CsVI2hwRy7Jxbd9urQOubpavBh7sM5FjJc1vlhcB5wPPt6xrVk3bkKwBVkp6EVjZrCNpmaQfN2M+DIxLegZ4FFgTEQ6JzRrpMclUImICuKjP8+PA9c3yH4CPtaljNkg+426WcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzhENiligSEkkXS9ohaWfTpK53+3xJ9zfbn5R0Som6ZjW0DomkI4AfAJcApwNXSjq9Z9h1wF8j4kPAd4Fvta1rVkuJPclyYGdEvBQR7wD3Aat7xqwGftIsPwBcJEkFapvNuBIhWQq83LW+q3mu75iI2A/sAY7r/UOSxppOj+MTExMFpmbWXomQ9Nsj9Ha8m84YIuKOiFgWEcuOO+6ADJkNRImQ7AJO7Fo/AXh1sjGSjgTeC7xRoLbZjCsRkk3AiKRTJc0DRul0duzW3enxCmBj+N7YNku0ak4HnWMMSTcBDwNHAHdFxDZJ3wDGI2IdcCfwU0k76exBRtvWNauldUgAImI9sL7nuVu7lv8OfKZELbPafMbdLOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZolazemukfQXSVuax/Ul6prV0PqbiV3N6VbSafiwSdK6iHi+Z+j9EXFT23pmtdVqTmc2a5X4jnu/5nTn9Bn3aUkXAC8AX4yIl3sHSBoDxgDmz5/P6Ojh0S9i48aNg55CMU899dSgp1BdreZ0vwZOiYiPA4/wv5an//9LXc3p5s2bV2BqZu1VaU4XERMR8Y9m9UfAWQXqmlVRpTmdpCVdq5cB2wvUNauiVnO6z0m6DNhPpzndNW3rmtVSqzndLcAtJWqZ1eYz7mYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzhENilnBIzBIOiVnCITFLlGpOd5ek1yRtnWS7JN3WNK97VtKZJeqa1VBqT3I3cPEU2y8BRprHGHB7obpmM65ISCLiMTrfXZ/MauCe6HgCWNjTHMJsaNU6JunXwG5ppdpmrRRpBDEN02lgd0AHR7NhUGtPkjawA3dwtOFUKyTrgKuaT7nOBfZExO5Ktc1aKfJ2S9K9wApgkaRdwNeBowAi4od0enKtAnYCbwPXlqhrVkOp5nRXJtsDuLFELbPafMbdLOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCxRq4PjCkl7JG1pHreWqGtWQ6mWQncDa4F7phjzeERcWqieWTW1OjiazVq1mtMBnCfpGTr9tr4cEdt6B3Q3p1u8eDFr1qypOL2Z88orrwx6CsWcffbZg55CdbUO3J8GTo6ITwDfB37Vb1B3c7qFCxdWmprZ1KqEJCLeioi9zfJ64ChJi2rUNmurSkgkLZakZnl5U3eiRm2ztmp1cLwCuEHSfmAfMNo0rDMberU6OK6l8xGx2azjM+5mCYfELOGQmCUcErOEQ2KWcEjMEg6JWcIhMUs4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExS7QOiaQTJT0qabukbZI+32eMJN0maaekZyWd2bauWS0lvpm4H/hSRDwtaQGwWdKGiHi+a8wlwEjzOAe4vflpNvRa70kiYndEPN0s/w3YDiztGbYauCc6ngAWSlrStrZZDUWPSSSdAnwSeLJn01Lg5a71XRwYJCSNSRqXNP7mm2+WnJrZISsWEknHAL8AvhARb/Vu7vMrB3RLcXM6G0alusofRScgP4uIX/YZsgs4sWv9BDrtTs2GXolPtwTcCWyPiO9MMmwdcFXzKde5wJ6I2N22tlkNJT7dOh/4LPCcpC3Nc18FToL/NqdbD6wCdgJvA9cWqGtWReuQRMTv6X/M0T0mgBvb1jIbBJ9xN0s4JGYJh8Qs4ZCYJRwSs4RDYpZwSMwSDolZwiExSzgkZgmHxCzhkJglHBKzhENilnBIzBIOiVmiVnO6FZL2SNrSPG5tW9esllrN6QAej4hLC9Qzq6pWczqzWatWczqA8yQ9I+k3kj5Ssq7ZTFKnR0OBP9RpTvc74Ju9vbckvQf4V0TslbQK+F5EjPT5G2PAWLN6GrCjyOSmtgh4vUKdGg6X11LrdZwcEcdng4qEpGlO9xDw8BS9t7rH/xlYFhED/4dKGo+IZYOeRwmHy2sZttdRpTmdpMXNOCQtb+pOtK1tVkOt5nRXADdI2g/sA0aj1Ps8sxlWqzndWmBt21oz5I5BT6Cgw+W1DNXrKHbgbna48mUpZok5GxJJF0va0dzH8eZBz+dQSbpL0muStg56Lm1N5xKnQZiTb7ckHQG8AKykc++UTcCVfS6lGXqSLgD20rnd3kcHPZ82mlsELum+xAm4fND/l7m6J1kO7IyIlyLiHeA+Ovd1nHUi4jHgjUHPo4RhvcRproZkWvdwtMFJLnGqaq6GZFr3cLTBSO6/Wd1cDYnv4TikpnH/zermakg2ASOSTpU0Dxilc19HG6Bp3n+zujkZkojYD9wEPEzn4PDnEbFtsLM6NJLuBf4InCZpl6TrBj2nFv5zidOnur7FumrQk5qTHwGbHYw5uScxOxgOiVnCITFLOCRmCYfELOGQmCUcErOEQ2KW+DdkBApC1RNNNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight2 = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                     [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(weight2.shape)\n",
    "\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='SAME') \n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img,0,3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    # enumerate하면 키, value 가 나온다!!!\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(one_img.reshape(3,3), cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4.]]]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([\n",
    "    [\n",
    "        [\n",
    "            [4],[3]],\n",
    "                   [[2],[1]]]], dtype=np.float32)\n",
    "\n",
    "pool = tf.nn.max_pool(image, ksize=[1,2,2,1] , strides = [1,1,1,1], padding='VALID') \n",
    "#ksize(필터사이즈) =위,오른,아래,왼 \n",
    "print(pool.shape)\n",
    "print(pool.eval()) # 하나의 값은 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-93d8da72a918>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images\n",
    "y_label = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-16cbe4455ef5>:51: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "training_epoch= 15\n",
    "batch_size =100\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=[None, 784])\n",
    "Y= tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28,28,1])\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01)) \n",
    "#stddeviation 표준화에서 1시그마 값을 0.01로 작게줌으로서 랜덤값을 줄이기\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME')\n",
    "#L1 SHAPE 은 -1(N개),*28*28*32\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides= [1,2,2,1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "#사이즈를 줄이는게 STIDE를 2로주면서 PADDING을 SAME으로 주면됌\n",
    "# L1 = -1*14*14*32\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides= [1,2,2,1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "# L2 = -1*7*7*64\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides= [1,2,2,1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "# l3 = -1, 4,4,128\n",
    "\n",
    "\n",
    "L3_float = tf.reshape(L3, [-1, 4*4*128])\n",
    "W4 = tf.get_variable('W4', shape=[4*4*128,625],initializer=tf.contrib.layers.xavier_initializer())\n",
    "B4 = tf.Variable(tf.random_normal([625]))\n",
    "dnn_1d = tf.nn.relu(tf.matmul(L3_float,W4)+B4)\n",
    "dnn_1d = tf.nn.dropout(dnn_1d, keep_prob=keep_prob)\n",
    "\n",
    "W5 =tf.get_variable('W5', shape=[625,256],initializer=tf.contrib.layers.xavier_initializer())\n",
    "B5 = tf.Variable(tf.random_normal([256]))\n",
    "dnn_2d = tf.nn.relu(tf.matmul(dnn_1d, W5)+B5)\n",
    "dnn_2d = tf.nn.dropout(dnn_2d, keep_prob=keep_prob)\n",
    "\n",
    "W6 = tf.get_variable('W6', shape=[256,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "B6 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(dnn_2d, W6)+B6\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 avg_cost :  0.7180851937830449\n",
      "Epoch : 1 avg_cost :  0.20303943041034728\n",
      "Epoch : 2 avg_cost :  0.15624224268238643\n",
      "Epoch : 3 avg_cost :  0.12968699230050496\n",
      "Epoch : 4 avg_cost :  0.11616179308600047\n",
      "Epoch : 5 avg_cost :  0.10836662400852544\n",
      "Epoch : 6 avg_cost :  0.09981754999607803\n",
      "Epoch : 7 avg_cost :  0.09712277342480696\n",
      "Epoch : 8 avg_cost :  0.09035509632053709\n",
      "Epoch : 9 avg_cost :  0.0880414338663898\n",
      "Epoch : 10 avg_cost :  0.08505872342566197\n",
      "Epoch : 11 avg_cost :  0.08266147791408004\n",
      "Epoch : 12 avg_cost :  0.08159494435076013\n",
      "Epoch : 13 avg_cost :  0.0787626020500267\n",
      "Epoch : 14 avg_cost :  0.07675500220619144\n"
     ]
    }
   ],
   "source": [
    "training_epoch = 15\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    avg_cost=0\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c,_ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y:batch_ys, keep_prob:0.5})\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"Epoch :\", epoch , \"avg_cost : \",avg_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
